---
title: "Week 1 Assignment"
author: "David Russo"
date: "1/15/2017"
output: word_document
---

* 2.4 #1

+ a. A flexible statistical model would perform           **better** than an inflexible statistical model when    *n* is extremely large and *p* is small. With a large   sample size and small number of predictors, we are less likely to overfit the data. Furthermore, flexible models will have lower bias than inflexible models which will contribute to a lower overall test error. 

  + b. A flexible statistical model would perform           **worse** than an inflexible statistical model when     *n* is small and *p* is extremely large. Using a flexible model with a small sample size would introduce a large amount of variance due to overfitting. 

  + c. A flexible statistical model would perform           **better** than an inflexible statistical model when the relationship between the predictors and the response is highly non-linear. Flexibile statistical models are better equipped to handle non-linearities than inflexible statistical models. Inflexible statistical models will often only detect linear relationships between predictors and the response. 

  + d. A flexible statistical model would perform           **worse** than an inflexible statistical model when the variance of the error terms is high. If the variance of the error terms is high, a flexible model will be likely to overfit the data, resulting in higher variance and higher test error. 

* 2.4 #2

  + a. Regression setting; inference; n = 500, p = profit, number of employees, industry
  
  + b. Classification setting; prediction; n = 20; p = price charged for the product, marketing budget, competition price
  
  + c. Regression setting; prediction; n = 52; p = % change in US market, % change in British market, % change in German market

* 2.4 #3

```{r setup_sketch_data, echo = FALSE, include = FALSE}

library(tidyverse)

# x axis will go from 1 to 20
x_axis <- seq(from = 1, to = 20, by = 1)

# bias decreases as model complexity increases
bias <- exp(-5*seq(from = 0.01, to = 1, by = 0.05))

# variance increases as model complexity increases
variance <- exp(-5*seq(from = 1, to = 0.01, by = -0.05))

# training error decreases as model complexity increases
training_error <- bias + runif(length(x_axis), 0.05, 0.055)

# testing error decreases initially and eventually increases
testing_error <- bias + variance + runif(length(x_axis), 0.05, 0.055)

# bayes_error error is the irreducible error
bayes_error <- rep(0.25, length(x_axis))

bv <- data.frame(`x axis` = x_axis, 
                 bias = bias,
                 variance = variance,
                 `training error` = training_error,
                 `testing error` = testing_error,
                 `bayes error` = bayes_error)

bv_long <- tidyr::gather(bv, `error source`, value, -1)

```
  + a. 
```{r plot_bias_variance_trade_off, echo = FALSE}

bias_var_plot <- 
  
  ggplot(bv_long, aes(x = x.axis, y = value)) + 
  
    geom_line(aes(col = `error source`)) +
  
      xlab("flexibility") + 
  
        ylab("")

bias_var_plot

```

      + i. The bias decreases with model flexibility because models that are more flexible are able to better fit the training data. As the fit improves, the bias decreases. 
      
      + ii. The variance increases with model flexibility because more flexible models tend to overfit the training data. When the model is applied to new data that wasn't used to train the model, the model will have a high degree of variation. This is because the highly flexible model can only model the training data, and not new data. 
      
      + iii. The training error decreases with model flexibility because more flexible models are able to model the training data well. As flexibility increases, data overfitting increases which decreases bias because the model is able to predict the training data well. 
      
      + iv. The testing error has a U-shape because it demonstrates the bias-variance trade off. As model flexibility increases, bias decreases but variance increases. The minimum point of the U-shape represents the degree of flexibility that yields the best trade off between bias and variance in terms of predictive ability on new data. Models that are not flexible enough will have high bias but low variance when tested on new data. Models that are too flexible will overfit the data and have low bias but high variance when tested on new data. 
      
      + v. The Bayes error is a horizontal line because it is constant. It represents the true noise in the data that cannot be captured by the model. 
  
  
* 2.4 #4

  + a. Classification
      + i. One example of a classification problem is predicting whether or not a customer will default on their mortgage based on their personal and financial data. The response is binary: 0 if they did not default and 1 if they did. The predictors are salary in dollars, down payment in dollars, age in years, gender, and savings account balance in dollars. The goal of this problem is prediction because the bank wants to make wise investment decisions and not give a mortgage to a risky customer. The bank doesn't necessarily care what causes a customer to default on their mortgage, but rather to be able to accurately predict if a customer will default on their mortgage.
      + ii. Another example of a classification problem is determining which health related attributes contribute to a patient's lung cancer status. The response is binary: 0 if they do not have lung cancer and 1 if they do have lung cancer. The predictors are age in years, gender, healthy eating status, exercise level, smoker status, and alcohol usage status. The goal of this problem is inference because a doctor will want to identify traits and habits that could lead to having lung cancer. It won't be useful to predict whether or not a given patient has cancer based on their attributes, but rather to instruct them to adopt different a different lifestyle to reduce their risk for cancer. 
      + iii. A final example of a classification problem is determining whether or not an airplane part will fail within the first three months of usage. The response is binary: 0 if the part will not fail and 1 if the part will fail. The predictors are plant where the part was manufactured and the amount of time it has been sitting on the shelf. The goal of this problem is prediction because the airplane operator will not be concerned with why the part is failing but rather whether or not it will fail. 
      
  + b. Regression
      + i. One example of a regression problem is predicting the amount of money that a customer will spend at a store based on their attributes. The response is dollars spent and the predictors are the gender of the customer, the occupation of the customer, the age of the customer, and the number of times that the customer goes shopping per month. The goal of the problem is inference so that the store can better understand how to market to their target audience. 
      + ii. Another example of a regression problem is predicting how many pounds a patient will lose while participating in a diet and exercise regiment being offered by a fitness club. If the customer doesn't lose their target amount of weight, they will receive a portion of their money back. The response is weight loss in pounds and the predictors are height, current weight, gender, and daily activity level. The goal of the problem is prediction because the fitness club does not want to put risky customers on their diet and exercise regiment. Their model must accurately predict weight loss or else they will lose money. 
      + iii. A final example of regression is predicting the amount of money for which a house will sell. The response is sale price in dollars and the predictors are square feet of the house, number of bathrooms, number of bedrooms, and distance from the nearest school. The goal of this problem is prediction because the seller wants to have accurate estimates of how much their house will sell for. They will not necessarily care what features contribute to a higher selling price. 
      
  + c. Cluster Analysis
      + i. One example of a cluster analysis is an animal adoption agency wants to classify their animals into 4 categories based on their attributes: good for a family with young kids, good for a family without young kids, good for young individuals/couples with no kids, and good for older individuals/couples with no kids. The animals could then be marketed in such a way that they would be more likely to be adopted by a fitting owner. This is a clustering problem because there aren't existing category labels for the animals on which to train a model.
      + ii. Another example of a cluster analysis is a marketing company is trying to segment their audience into distinct groups to provide targeted advertising. This is a clustering problem because there aren't pre-existing labels for their target audience and they must instead be determined based on the attributes of their audience.
      + iii. A final example of a cluster analysis is determining which category a given investor falls into: risk averse, risk neutral, and willing to take investment risks. With this information, the bank could offer targeted services to a given individual based on their attributes. This is a clustering problem because there are no pre-existing labels and hence no training data on which to train a model. 

* 2.4 #8

  + a. Set working directory and load data
```{r 2.8_a, echo = TRUE, include = TRUE}



workDir <- "/Users/davidrusso/Documents/Classes/Applied Data Analysis/Assignments"

college <- read.csv(paste(workDir, "College.csv", sep = "/"), header = TRUE)

```

  + b. Explore the data 
```{r 2.8_b, echo = TRUE, include = TRUE}

# assign row names to the dataset college
rownames(college) <- college[, 1]
college[1:6, 1:6]

# remove the column containing the college names
college <- college[, -1]
college[1:6, 1:6]

```

  + c. Perforom exploratory data analysis on *college* data set
      + i. summary()
```{r summary_function, echo = TRUE, include = TRUE}

summary(college)

```
      + ii. pairs()
```{r pairs_function, echo = TRUE, include = TRUE}

pairs(college[, 1:10])

```
     
      + iii. plot()
```{r plot_function, echo = TRUE, include = TRUE}

plot(college$Private, college$Outstate, xlab = "Private School Indicator", ylab = "Out of State")

```
      
      + iv. Create new variable
```{r create_vars, echo = TRUE, include = TRUE}

# create Elite indicator for colleges where more than 50% of the students are from the top 10% of their high schoo class
Elite <- rep("No", nrow(college))
Elite[college$Top10perc > 50] <- "Yes"
Elite <- as.factor(Elite)
college <- data.frame(college, Elite)

# determine counts for elite colleges
summary(college$Elite)

# produce boxplots for Elite and Outstate
plot(college$Elite, college$Outstate)

```
     
      + v. hist()
```{r hist_function, echo = TRUE, include = TRUE}

par(mfrow = c(2,2))
hist(college$Apps, breaks = 10, main = "Applications Received \n Bins = 10")
hist(college$Room.Board, breaks = 20, main = "Room and Board costs \n Bins = 20")
hist(college$PhD, breaks = 50, main = "Percentage of Faculty with PhDs \n Bins = 50")
hist(college$Grad.Rate, breaks = 100, main = "Graduation Rate \n Bins = 100")

```
     
      + vi. Further exploration
```{r further_exploration, echo = TRUE, include = TRUE}

plot(college$Top10perc,
     college$Accept/college$Apps,
     xlab = "Pct. new students from top 10% of H.S. class Top25perc",
     ylab = "Acceptance Rate")

plot(college$Private,
     college$Accept/college$Apps,
     xlab = "Private School Indicator",
     ylab = "Acceptance Rate")

plot(college$Grad.Rate,
     college$Accept/college$Apps,
     xlab = "Graduation Rate",
     ylab = "Acceptance Rate")

```


As the number of students from the top 10% of their high school class increases, the acceptance rate decreases. This would indicate that colleges that receive more competitive applications are able to be more selective. The median acceptance rate is slightly higher for private schools but they have many more outlier examples of lower acceptance rates. Graduation rate is generally higher for schools with lower acceptance rates. In general, it appears that stronger students tend to go to more selective schools and that selective schools tend to have higher graduation rates. The most selective schools tend to be private.  