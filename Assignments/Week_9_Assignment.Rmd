---
title: "Week 9 Assignment"
author: "David Russo"
date: "3/12/2017"
output: pdf_document
---

```{r overhead, echo = TRUE, include = FALSE}
library(tidyverse)
library(ISLR)
```

10.7 #7
```{r demonstration_strange_wording, echo = TRUE, include = TRUE}
# load the data
data("USArrests")

# scale the data so that each variable has a mean of 0 and a variance of 1
usa_scaled <- as.data.frame(scale(USArrests))
# verify that the scaled data's variables all have mean 0 and variance 1
apply(usa_scaled, 2, function(x) round(c(mean(x), var(x)), 2))

# create data frame of combinations of rows of usa_scaled data set
# there are choose(50, 2) = 1225 ways to choose 2 observations out of 50
combs <- t(combn(nrow(usa_scaled), 2))
head(combs)

###----------------- Determine Correlations ----------------------------

# cycle through combs to get each correlation between rows
one_minus_cors <- rep(0, nrow(combs))

# create function for getting correlations between each observation
one_minus_cor_usa <- function(x){
  res <- cor(as.numeric(usa_scaled[combs[x, 1], ]),
             as.numeric(usa_scaled[combs[x, 2], ]))
  res <- 1 - res
  res
}

# determine 1 - r_ij for each pair of observations
one_minus_cors <- sapply(1:nrow(combs), function(x) one_minus_cor_usa(x))

###----------------- Determine Squared Euclidean Distances --------------

# cycle through combs to get distance between rows
distances <- dist(usa_scaled)^2

###----------------- Determine Proportionality -------------------
summary(one_minus_cors/distances)

hist(one_minus_cors/distances)

```

As can be seen from the summary above, there is no evidence of proportionality. If there were proportionality, there would only be one value. I believe the wording of this question is either wrong or simply hard to understand. The question refers to distances and correlations between the $i^{th}$ and $j^{th}$ observations, which would lead me to believe it is referring to the rows of the data set (i.e., 50 rows; one per state). If the authors meant to refer to the distances and correlations between $i^{th}$ and $j^{th}$ variables (i.e., the 4 variables of Murder, Assault, UrbanPop, and Rape), then there is constant proportionality. This is shown below.

```{r possible_wording_meaning}
# squared distance matrix 
distance_matrix <- dist(t(usa_scaled))^2
distance_matrix

# 1 - correlation matrix
one_minus_cor_mat <- as.dist(1-cor(usa_scaled))
one_minus_cor_mat

# demonstration of proportionality 
distance_matrix/one_minus_cor_mat
```

10.7 #10

  * a)
```{r 10a, echo = TRUE, include = TRUE}
# generate raw data matrix 
set.seed(2017)
dat <- matrix(rnorm(60*50) + rep(c(2, -5, 7), each = 20), ncol = 50)
true_labels <- rep(c("group 1", "group 2", "group 3"), each = 20)

# get means for first 20 rows, representing the first class
mean(dat[1:20, ])

# get means for the second 20 rows, representing the second class
mean(dat[21:40, ])

# get means for the final 20 rows, representing the third class
mean(dat[41:60, ])
```

  * b)
```{r 10b, echo = TRUE, include = TRUE}
# perform principal components
pr_10b <- prcomp(dat, scale = TRUE)

# plot the first two principal components
plot_dat <- as.data.frame(pr_10b$x[, c(1, 2)])
plot_dat$label <- true_labels

plot_dat %>%
  ggplot(aes(x = PC1, y = PC2)) +
  geom_point(aes(col = true_labels)) + 
  xlab("Principal Component 1") + 
  ylab("Principal Component 2")
```

  * c)
```{r 10c, echo = TRUE, include = TRUE}
km_10c <- kmeans(dat, 3, nstart = 20)
table(true_labels, km_10c$cluster)
```

  * d)
```{r 10d, echo = TRUE, include = TRUE}
km_10d <- kmeans(dat, 2, nstart = 20)
table(true_labels, km_10d$cluster)
```
When using K = 2 clusters, the clusters split cleanly between the three labels. Cluster 1 has group 1 and group 3 while Cluster 2 has group 2. Group 1 has a mean of 2 and Group 3 has a mean of 7, both corresponding to the positive means. Group 2 has a mean of -5, which is the only negative mean group. With two clusters, the groups are split into positive and negative groups.


  * e)
```{r 10e, echo = TRUE, include = TRUE}
km_10e <- kmeans(dat, 4, nstart = 20)
table(true_labels, km_10e$cluster)

# numeric summaries of the three true labels
summary(as.numeric(dat[1:20, ]))
summary(as.numeric(dat[21:40, ]))
summary(as.numeric(dat[41:60, ]))

```
When using K = 4 clusters, Group 1 is split between cluster 1 and cluster 3. Group 2 is assigned completely to cluster 2, and group 3 is assigned completely to cluster 4. As can be seen from the numeric summaries, Group 2 has only negative values while Group 3 has only positive values. Group 1 has mostly positive values but has some negative values as well. This is perhaps the reason why Group 1 is split into 2 clusters in this scenario. 

  * f)
```{r 10f, echo = TRUE, include = TRUE}
km_10f <- kmeans(pr_10b$x[, c(1, 2)],
                 3,
                 nstart = 20)
table(true_labels, km_10f$cluster)
```

When performing clustering on the principal components, the clusters again are perfectly divided into the three groups.

  * g)
```{r 10g, echo = TRUE, include = TRUE}
km_10g <- kmeans(scale(dat), 3, nstart = 20)
table(true_labels, km_10g$cluster)
```

When performing clustering on the scaled data, we again see perfect separation. However, the labels are different than they have been in the past. Group 1 maps to Cluster 1, Group 2 maps to Cluster 3, and Group 3 maps to Cluster 2. 



