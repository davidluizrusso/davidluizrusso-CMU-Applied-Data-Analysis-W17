---
title: "Week  6 Assignment"
author: "David Russo"
date: "2/18/2017"
output:
  pdf_document: default
  html_document: default
---

* 4.7 #10
```{r set_up, echo = FALSE, include = FALSE}
# load libraries
library(tidyverse)
library(MASS)
library(ISLR)
library(class)
# load data
data(Weekly)
```

  + a.
```{r a_numeric_summaries, echo = FALSE}
count_results <- 
Weekly %>%
  group_by(Direction) %>%
    summarise(Count = n(),
              Percent = paste0(round(Count/nrow(Weekly), 2)*100, "%"))
knitr::kable(count_results)

mean_covariates <- 
Weekly %>%
  group_by(Direction) %>%
    summarise(`Mean Lag1` = round(mean(Lag1), 4),
              `Mean Lag2` = round(mean(Lag2), 4),
              `Mean Lag3` = round(mean(Lag3), 4),
              `Mean Lag4` = round(mean(Lag4), 4), 
              `Mean Lag5` = round(mean(Lag5), 4),
              `Mean Volume` = round(mean(Volume), 4),
              `Mean Today` = round(mean(Today), 4))
knitr::kable(mean_covariates)


knitr::kable(cor(Weekly[!names(Weekly) %in% "Direction"]))
```

We see that for the market data, about $56$% of the weeks had positive market performance while $44$% of the weeks had negative market performance. The value of $today$ does not appear to be highly correlated with any of the $lag$ or $volume$ covariates. 

```{r a_graphical_summaries, echo = FALSE}
Weekly_lag_long <-
  Weekly %>%
    dplyr::select(Lag1, Lag2, Lag3, Lag4, Lag5, Direction) %>%
      gather("Lag", "Value", 1:5) %>%
        ggplot(aes(x = Direction, y = Value)) + 
          geom_boxplot()
Weekly_lag_long

volPlot <- 
  Weekly %>%
    ggplot(aes(x = Year, y = Volume)) + 
      geom_point()
volPlot

mean_year <-
Weekly %>%
  group_by(Year) %>%
    summarise(`mean weekly return` = round(mean(Today), 4)) %>%
      ggplot(aes(x = Year, y = `mean weekly return`)) +
        geom_line()
mean_year
```

From the side-by-side boxplots, we see that markets finished up and down with relatively equal magnitudes. Furthermore, we can see that the number of trades has increased exponentially since 1990. Lastly, we can see that the average weekly return has varied from year to year, with several more down years between the years 2000 and 2010 vs 1990 and 2000. 

  + b. 
```{r b_full_log_reg}

glm.b <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
             data = Weekly,
             family = binomial)

summary(glm.b)

```

Only the variable Lag2 appears to be a significant predictor of direction. 

  + c.
  
As can be seen from the confusion matrix below, the model tends to predict that the market will go up, as `r round((430+557)/(430+557+54+48), 2)*100`% of the predicted values were for the market going up. When the model predicts that the market will go up, it is correct `r round(557/(430+557), 2)*100`% of the time. When the model predicts that the market will go down, it is right `r round(54/(54+48), 2)*100`% of the time. Overall, the model has a `r round((54+557)/(54+48+430+557), 2)*100`% accuracy rate.The model is overly optimisitc, as the stock market only went up around 56% of the time. 
```{r c_confusion_matrix}

# determine what is being modeled
contrasts(Weekly$Direction)
# get predictions using 0.5 as the probability threshold 
glm.b.preds <- ifelse(predict(glm.b, type = "response") < 0.5, "Down", "Up")
# get confusion matrix of predicted directions and actual directions
table(glm.b.preds, Weekly$Direction)

```

   + d.

As can be seen from the confusion matrix below, the overall accuracy on the test data is `r round((9+56)/(9+56+5+34), 2)*100`%.
```{r d_validation_log_reg}
# Create training and testing sets
Weekly_train <- dplyr::filter(Weekly, Year %in% 1990:2008)
Weekly_test <- dplyr::filter(Weekly, Year %in% 2009:2010)

# fit model
glm.d <- glm(Direction ~ Lag2,
             data = Weekly_train,
             family = binomial)
# get predicted responses
glm.d.preds <- ifelse(predict(glm.d, newdata = Weekly_test, type = "response") < 0.50,
                       "Down",
                       "Up")
 
# create confusion matrix
table(glm.d.preds, Weekly_test$Direction)
```
  + e.

As can be seen from the confusion matrix below, the predictions for linear discriminant analysis mirror those of logistic regression. The overall accuracy rate is again `r round((9+56)/(9+5+34+56), 2)*100`%.
```{r e_validation_lda}
# fit lda model
lda.e <- lda(Direction ~ Lag2,
             data = Weekly_train)

# extract predictions
lda.pred <- predict(lda.e, newdata = Weekly_test)$class

# create confusion matrix
table(lda.pred, Weekly_test$Direction)
```

  + f.

As can be seen from the confusion matrix below, the predictions for quadratic discriminant analysis are always "Up". The overall accuracy is `r round(61/(61+43), 2)*100`%. It is possible that a cut-off other than 0.50 will yield improved accuracy. 
```{r f_validation_qda}
qda.e <- qda(Direction ~ Lag2,
             data = Weekly_train)

# extract predictions
qda.pred <- predict(qda.e, newdata = Weekly_test)$class

# create confusion matrix
table(qda.pred, Weekly_test$Direction)
```

  + g.
  
As can be seen from the confusion matrix below, KNN with K = 1 has an overall accuracy of `r round((21+31)/(21+31+30+22), 2)*100`%.  
```{r g_validation_knn1}
# set random number seed for tie breaking
set.seed(1)

# create training and testing sets
train.X <- dplyr::select(Weekly_train, Lag2)
test.X <- dplyr::select(Weekly_test, Lag2)
train.Y <- Weekly_train %>% dplyr::select(Direction) %>% collapse %>% .[[1]]

# make predictions
knn.pred <- class::knn(train.X, test.X, train.Y, k = 1)

# create confusion matrix
table(knn.pred, Weekly_test$Direction)

```